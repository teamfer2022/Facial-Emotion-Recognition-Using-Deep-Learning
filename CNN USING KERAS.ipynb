{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48485621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "#from keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a680c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv(\"C:/Users/Shreya/Desktop/fer2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb7bc984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "449/449 [==============================] - 355s 788ms/step - loss: 1.7328 - accuracy: 0.2903 - val_loss: 1.5861 - val_accuracy: 0.3859\n",
      "Epoch 2/100\n",
      "449/449 [==============================] - 274s 610ms/step - loss: 1.5220 - accuracy: 0.3973 - val_loss: 1.3902 - val_accuracy: 0.4622\n",
      "Epoch 3/100\n",
      "449/449 [==============================] - 273s 609ms/step - loss: 1.4001 - accuracy: 0.4567 - val_loss: 1.3344 - val_accuracy: 0.4845\n",
      "Epoch 4/100\n",
      "449/449 [==============================] - 275s 613ms/step - loss: 1.3379 - accuracy: 0.4793 - val_loss: 1.3138 - val_accuracy: 0.4781\n",
      "Epoch 5/100\n",
      "449/449 [==============================] - 273s 609ms/step - loss: 1.2956 - accuracy: 0.5001 - val_loss: 1.2549 - val_accuracy: 0.5149\n",
      "Epoch 6/100\n",
      "449/449 [==============================] - 274s 611ms/step - loss: 1.2595 - accuracy: 0.5162 - val_loss: 1.2275 - val_accuracy: 0.5263\n",
      "Epoch 7/100\n",
      "449/449 [==============================] - 272s 607ms/step - loss: 1.2285 - accuracy: 0.5317 - val_loss: 1.2059 - val_accuracy: 0.5383\n",
      "Epoch 8/100\n",
      "449/449 [==============================] - 274s 610ms/step - loss: 1.2002 - accuracy: 0.5428 - val_loss: 1.1962 - val_accuracy: 0.5525\n",
      "Epoch 9/100\n",
      "449/449 [==============================] - 274s 611ms/step - loss: 1.1798 - accuracy: 0.5482 - val_loss: 1.1744 - val_accuracy: 0.5511\n",
      "Epoch 10/100\n",
      "449/449 [==============================] - 275s 613ms/step - loss: 1.1628 - accuracy: 0.5542 - val_loss: 1.1597 - val_accuracy: 0.5570\n",
      "Epoch 11/100\n",
      "449/449 [==============================] - 272s 607ms/step - loss: 1.1360 - accuracy: 0.5678 - val_loss: 1.1772 - val_accuracy: 0.5489\n",
      "Epoch 12/100\n",
      "449/449 [==============================] - 268s 598ms/step - loss: 1.1244 - accuracy: 0.5688 - val_loss: 1.1575 - val_accuracy: 0.5603\n",
      "Epoch 13/100\n",
      "449/449 [==============================] - 270s 602ms/step - loss: 1.1019 - accuracy: 0.5781 - val_loss: 1.1645 - val_accuracy: 0.5570\n",
      "Epoch 14/100\n",
      "449/449 [==============================] - 270s 602ms/step - loss: 1.0911 - accuracy: 0.5803 - val_loss: 1.1418 - val_accuracy: 0.5737\n",
      "Epoch 15/100\n",
      "449/449 [==============================] - 272s 605ms/step - loss: 1.0657 - accuracy: 0.5933 - val_loss: 1.1575 - val_accuracy: 0.5687\n",
      "Epoch 16/100\n",
      "449/449 [==============================] - 275s 613ms/step - loss: 1.0511 - accuracy: 0.6001 - val_loss: 1.1460 - val_accuracy: 0.5667\n",
      "Epoch 17/100\n",
      "449/449 [==============================] - 272s 606ms/step - loss: 1.0363 - accuracy: 0.6051 - val_loss: 1.1817 - val_accuracy: 0.5639\n",
      "Epoch 18/100\n",
      "449/449 [==============================] - 270s 600ms/step - loss: 1.0221 - accuracy: 0.6096 - val_loss: 1.1465 - val_accuracy: 0.5701\n",
      "Epoch 19/100\n",
      "449/449 [==============================] - 269s 599ms/step - loss: 1.0038 - accuracy: 0.6155 - val_loss: 1.1545 - val_accuracy: 0.5865\n",
      "Epoch 20/100\n",
      "449/449 [==============================] - 268s 596ms/step - loss: 0.9881 - accuracy: 0.6229 - val_loss: 1.1584 - val_accuracy: 0.5793\n",
      "Epoch 21/100\n",
      "449/449 [==============================] - 270s 602ms/step - loss: 0.9761 - accuracy: 0.6306 - val_loss: 1.1612 - val_accuracy: 0.5673\n",
      "Epoch 22/100\n",
      "449/449 [==============================] - 267s 595ms/step - loss: 0.9620 - accuracy: 0.6311 - val_loss: 1.1729 - val_accuracy: 0.5748\n",
      "Epoch 23/100\n",
      "449/449 [==============================] - 269s 599ms/step - loss: 0.9448 - accuracy: 0.6420 - val_loss: 1.1604 - val_accuracy: 0.5709\n",
      "Epoch 24/100\n",
      "449/449 [==============================] - 271s 604ms/step - loss: 0.9327 - accuracy: 0.6437 - val_loss: 1.1715 - val_accuracy: 0.5860\n",
      "Epoch 25/100\n",
      "449/449 [==============================] - 268s 597ms/step - loss: 0.9134 - accuracy: 0.6528 - val_loss: 1.1859 - val_accuracy: 0.5609\n",
      "Epoch 26/100\n",
      "449/449 [==============================] - 269s 599ms/step - loss: 0.9093 - accuracy: 0.6529 - val_loss: 1.1723 - val_accuracy: 0.5793\n",
      "Epoch 27/100\n",
      "449/449 [==============================] - 268s 596ms/step - loss: 0.8909 - accuracy: 0.6629 - val_loss: 1.1999 - val_accuracy: 0.5626\n",
      "Epoch 28/100\n",
      "449/449 [==============================] - 270s 601ms/step - loss: 0.8772 - accuracy: 0.6664 - val_loss: 1.2079 - val_accuracy: 0.5706\n",
      "Epoch 29/100\n",
      "449/449 [==============================] - 268s 596ms/step - loss: 0.8603 - accuracy: 0.6724 - val_loss: 1.1853 - val_accuracy: 0.5717\n",
      "Epoch 30/100\n",
      "449/449 [==============================] - 280s 623ms/step - loss: 0.8477 - accuracy: 0.6765 - val_loss: 1.2001 - val_accuracy: 0.5740\n",
      "Epoch 31/100\n",
      "449/449 [==============================] - 283s 631ms/step - loss: 0.8426 - accuracy: 0.6827 - val_loss: 1.2209 - val_accuracy: 0.5659\n",
      "Epoch 32/100\n",
      "449/449 [==============================] - 276s 615ms/step - loss: 0.8288 - accuracy: 0.6829 - val_loss: 1.1845 - val_accuracy: 0.5795\n",
      "Epoch 33/100\n",
      "449/449 [==============================] - 275s 612ms/step - loss: 0.8155 - accuracy: 0.6909 - val_loss: 1.2326 - val_accuracy: 0.5768\n",
      "Epoch 34/100\n",
      "449/449 [==============================] - 294s 654ms/step - loss: 0.8094 - accuracy: 0.6952 - val_loss: 1.2196 - val_accuracy: 0.5681\n",
      "Epoch 35/100\n",
      "449/449 [==============================] - 287s 640ms/step - loss: 0.7925 - accuracy: 0.7011 - val_loss: 1.2494 - val_accuracy: 0.5756\n",
      "Epoch 36/100\n",
      "449/449 [==============================] - 277s 617ms/step - loss: 0.7887 - accuracy: 0.7015 - val_loss: 1.2128 - val_accuracy: 0.5762\n",
      "Epoch 37/100\n",
      "449/449 [==============================] - 279s 622ms/step - loss: 0.7682 - accuracy: 0.7101 - val_loss: 1.3112 - val_accuracy: 0.5695\n",
      "Epoch 38/100\n",
      "449/449 [==============================] - 277s 617ms/step - loss: 0.7591 - accuracy: 0.7117 - val_loss: 1.2899 - val_accuracy: 0.5667\n",
      "Epoch 39/100\n",
      "449/449 [==============================] - 277s 616ms/step - loss: 0.7528 - accuracy: 0.7144 - val_loss: 1.2793 - val_accuracy: 0.5762\n",
      "Epoch 40/100\n",
      "449/449 [==============================] - 276s 614ms/step - loss: 0.7385 - accuracy: 0.7214 - val_loss: 1.2816 - val_accuracy: 0.5759\n",
      "Epoch 41/100\n",
      "449/449 [==============================] - 279s 620ms/step - loss: 0.7275 - accuracy: 0.7266 - val_loss: 1.2691 - val_accuracy: 0.5832\n",
      "Epoch 42/100\n",
      "449/449 [==============================] - 276s 615ms/step - loss: 0.7245 - accuracy: 0.7291 - val_loss: 1.2820 - val_accuracy: 0.5837\n",
      "Epoch 43/100\n",
      "449/449 [==============================] - 278s 618ms/step - loss: 0.7164 - accuracy: 0.7299 - val_loss: 1.3021 - val_accuracy: 0.5762\n",
      "Epoch 44/100\n",
      "449/449 [==============================] - 276s 614ms/step - loss: 0.7022 - accuracy: 0.7377 - val_loss: 1.2993 - val_accuracy: 0.5723\n",
      "Epoch 45/100\n",
      "449/449 [==============================] - 278s 618ms/step - loss: 0.6922 - accuracy: 0.7398 - val_loss: 1.3685 - val_accuracy: 0.5681\n",
      "Epoch 46/100\n",
      "449/449 [==============================] - 275s 612ms/step - loss: 0.6851 - accuracy: 0.7461 - val_loss: 1.3200 - val_accuracy: 0.5678\n",
      "Epoch 47/100\n",
      "449/449 [==============================] - 276s 615ms/step - loss: 0.6762 - accuracy: 0.7506 - val_loss: 1.3337 - val_accuracy: 0.5765\n",
      "Epoch 48/100\n",
      "449/449 [==============================] - 275s 613ms/step - loss: 0.6682 - accuracy: 0.7509 - val_loss: 1.3608 - val_accuracy: 0.5779\n",
      "Epoch 49/100\n",
      "449/449 [==============================] - 276s 616ms/step - loss: 0.6747 - accuracy: 0.7512 - val_loss: 1.3799 - val_accuracy: 0.5731\n",
      "Epoch 50/100\n",
      "449/449 [==============================] - 279s 621ms/step - loss: 0.6467 - accuracy: 0.7604 - val_loss: 1.4009 - val_accuracy: 0.5717\n",
      "Epoch 51/100\n",
      "449/449 [==============================] - 272s 605ms/step - loss: 0.6393 - accuracy: 0.7620 - val_loss: 1.3781 - val_accuracy: 0.5631\n",
      "Epoch 52/100\n",
      "449/449 [==============================] - 269s 600ms/step - loss: 0.6419 - accuracy: 0.7605 - val_loss: 1.3659 - val_accuracy: 0.5729\n",
      "Epoch 53/100\n",
      "449/449 [==============================] - 268s 597ms/step - loss: 0.6361 - accuracy: 0.7644 - val_loss: 1.3998 - val_accuracy: 0.5734\n",
      "Epoch 54/100\n",
      "449/449 [==============================] - 270s 602ms/step - loss: 0.6254 - accuracy: 0.7675 - val_loss: 1.3975 - val_accuracy: 0.5790\n",
      "Epoch 55/100\n",
      "449/449 [==============================] - 270s 602ms/step - loss: 0.6200 - accuracy: 0.7718 - val_loss: 1.3919 - val_accuracy: 0.5770\n",
      "Epoch 56/100\n",
      "449/449 [==============================] - 270s 601ms/step - loss: 0.6106 - accuracy: 0.7738 - val_loss: 1.3845 - val_accuracy: 0.5754\n",
      "Epoch 57/100\n",
      "449/449 [==============================] - 268s 597ms/step - loss: 0.6046 - accuracy: 0.7760 - val_loss: 1.4330 - val_accuracy: 0.5723\n",
      "Epoch 58/100\n",
      "449/449 [==============================] - 271s 604ms/step - loss: 0.5972 - accuracy: 0.7815 - val_loss: 1.3907 - val_accuracy: 0.5773\n",
      "Epoch 59/100\n",
      "449/449 [==============================] - 271s 603ms/step - loss: 0.5875 - accuracy: 0.7817 - val_loss: 1.4501 - val_accuracy: 0.5690\n",
      "Epoch 60/100\n",
      "449/449 [==============================] - 270s 602ms/step - loss: 0.5894 - accuracy: 0.7824 - val_loss: 1.4448 - val_accuracy: 0.5678\n",
      "Epoch 61/100\n",
      "449/449 [==============================] - 273s 608ms/step - loss: 0.5732 - accuracy: 0.7871 - val_loss: 1.4425 - val_accuracy: 0.5706\n",
      "Epoch 62/100\n",
      "449/449 [==============================] - 271s 603ms/step - loss: 0.5667 - accuracy: 0.7944 - val_loss: 1.5029 - val_accuracy: 0.5790\n",
      "Epoch 63/100\n",
      "449/449 [==============================] - 276s 615ms/step - loss: 0.5668 - accuracy: 0.7929 - val_loss: 1.4210 - val_accuracy: 0.5720\n",
      "Epoch 64/100\n",
      "449/449 [==============================] - 271s 604ms/step - loss: 0.5550 - accuracy: 0.7978 - val_loss: 1.4574 - val_accuracy: 0.5690\n",
      "Epoch 65/100\n",
      "449/449 [==============================] - 275s 613ms/step - loss: 0.5569 - accuracy: 0.7926 - val_loss: 1.4999 - val_accuracy: 0.5776\n",
      "Epoch 66/100\n",
      "449/449 [==============================] - 271s 603ms/step - loss: 0.5460 - accuracy: 0.7987 - val_loss: 1.4654 - val_accuracy: 0.5821\n",
      "Epoch 67/100\n",
      "449/449 [==============================] - 272s 607ms/step - loss: 0.5367 - accuracy: 0.8019 - val_loss: 1.4593 - val_accuracy: 0.5723\n",
      "Epoch 68/100\n",
      "449/449 [==============================] - 271s 603ms/step - loss: 0.5376 - accuracy: 0.8049 - val_loss: 1.4886 - val_accuracy: 0.5726\n",
      "Epoch 69/100\n",
      "449/449 [==============================] - 274s 610ms/step - loss: 0.5344 - accuracy: 0.8060 - val_loss: 1.5055 - val_accuracy: 0.5628\n",
      "Epoch 70/100\n",
      "449/449 [==============================] - 270s 602ms/step - loss: 0.5294 - accuracy: 0.8078 - val_loss: 1.4817 - val_accuracy: 0.5670\n",
      "Epoch 71/100\n",
      "449/449 [==============================] - 271s 604ms/step - loss: 0.5240 - accuracy: 0.8075 - val_loss: 1.5945 - val_accuracy: 0.5587\n",
      "Epoch 72/100\n",
      "449/449 [==============================] - 271s 604ms/step - loss: 0.5221 - accuracy: 0.8137 - val_loss: 1.5092 - val_accuracy: 0.5737\n",
      "Epoch 73/100\n",
      "449/449 [==============================] - 269s 599ms/step - loss: 0.5184 - accuracy: 0.8116 - val_loss: 1.5361 - val_accuracy: 0.5723\n",
      "Epoch 74/100\n",
      "449/449 [==============================] - 279s 623ms/step - loss: 0.5100 - accuracy: 0.8179 - val_loss: 1.6131 - val_accuracy: 0.5670\n",
      "Epoch 75/100\n",
      "449/449 [==============================] - 276s 614ms/step - loss: 0.5033 - accuracy: 0.8164 - val_loss: 1.5484 - val_accuracy: 0.5592\n",
      "Epoch 76/100\n",
      "449/449 [==============================] - 281s 626ms/step - loss: 0.5095 - accuracy: 0.8150 - val_loss: 1.5055 - val_accuracy: 0.5704\n",
      "Epoch 77/100\n",
      "449/449 [==============================] - 275s 613ms/step - loss: 0.4982 - accuracy: 0.8167 - val_loss: 1.5833 - val_accuracy: 0.5670\n",
      "Epoch 78/100\n",
      "449/449 [==============================] - 278s 619ms/step - loss: 0.4836 - accuracy: 0.8251 - val_loss: 1.5916 - val_accuracy: 0.5762\n",
      "Epoch 79/100\n",
      "449/449 [==============================] - 275s 613ms/step - loss: 0.4885 - accuracy: 0.8242 - val_loss: 1.5558 - val_accuracy: 0.5692\n",
      "Epoch 80/100\n",
      "449/449 [==============================] - 275s 612ms/step - loss: 0.4837 - accuracy: 0.8262 - val_loss: 1.6699 - val_accuracy: 0.5715\n",
      "Epoch 81/100\n",
      "449/449 [==============================] - 276s 615ms/step - loss: 0.4825 - accuracy: 0.8258 - val_loss: 1.5788 - val_accuracy: 0.5756\n",
      "Epoch 82/100\n",
      "449/449 [==============================] - 276s 614ms/step - loss: 0.4863 - accuracy: 0.8265 - val_loss: 1.5118 - val_accuracy: 0.5695\n",
      "Epoch 83/100\n",
      "449/449 [==============================] - 276s 616ms/step - loss: 0.4717 - accuracy: 0.8310 - val_loss: 1.6028 - val_accuracy: 0.5659\n",
      "Epoch 84/100\n",
      "449/449 [==============================] - 276s 614ms/step - loss: 0.4694 - accuracy: 0.8304 - val_loss: 1.6058 - val_accuracy: 0.5717\n",
      "Epoch 85/100\n",
      "449/449 [==============================] - 279s 621ms/step - loss: 0.4644 - accuracy: 0.8326 - val_loss: 1.5960 - val_accuracy: 0.5673\n",
      "Epoch 86/100\n",
      "449/449 [==============================] - 279s 622ms/step - loss: 0.4694 - accuracy: 0.8325 - val_loss: 1.6149 - val_accuracy: 0.5787\n",
      "Epoch 87/100\n",
      "449/449 [==============================] - 272s 605ms/step - loss: 0.4617 - accuracy: 0.8358 - val_loss: 1.5564 - val_accuracy: 0.5756\n",
      "Epoch 88/100\n",
      "449/449 [==============================] - 270s 602ms/step - loss: 0.4674 - accuracy: 0.8328 - val_loss: 1.5805 - val_accuracy: 0.5692\n",
      "Epoch 89/100\n",
      "449/449 [==============================] - 272s 605ms/step - loss: 0.4570 - accuracy: 0.8375 - val_loss: 1.6379 - val_accuracy: 0.5639\n",
      "Epoch 90/100\n",
      "449/449 [==============================] - 268s 597ms/step - loss: 0.4451 - accuracy: 0.8414 - val_loss: 1.5919 - val_accuracy: 0.5715\n",
      "Epoch 91/100\n",
      "449/449 [==============================] - 271s 603ms/step - loss: 0.4476 - accuracy: 0.8419 - val_loss: 1.6297 - val_accuracy: 0.5592\n",
      "Epoch 92/100\n",
      "449/449 [==============================] - 268s 597ms/step - loss: 0.4463 - accuracy: 0.8421 - val_loss: 1.6506 - val_accuracy: 0.5653\n",
      "Epoch 93/100\n",
      "449/449 [==============================] - 272s 606ms/step - loss: 0.4437 - accuracy: 0.8419 - val_loss: 1.6794 - val_accuracy: 0.5648\n",
      "Epoch 94/100\n",
      "449/449 [==============================] - 276s 615ms/step - loss: 0.4560 - accuracy: 0.8405 - val_loss: 1.6171 - val_accuracy: 0.5692\n",
      "Epoch 95/100\n",
      "449/449 [==============================] - 275s 612ms/step - loss: 0.4297 - accuracy: 0.8474 - val_loss: 1.6731 - val_accuracy: 0.5759\n",
      "Epoch 96/100\n",
      "449/449 [==============================] - 277s 616ms/step - loss: 0.4283 - accuracy: 0.8476 - val_loss: 1.6352 - val_accuracy: 0.5701\n",
      "Epoch 97/100\n",
      "449/449 [==============================] - 275s 613ms/step - loss: 0.4292 - accuracy: 0.8482 - val_loss: 1.6729 - val_accuracy: 0.5748\n",
      "Epoch 98/100\n",
      "449/449 [==============================] - 277s 616ms/step - loss: 0.4209 - accuracy: 0.8514 - val_loss: 1.6804 - val_accuracy: 0.5748\n",
      "Epoch 99/100\n",
      "449/449 [==============================] - 277s 618ms/step - loss: 0.4309 - accuracy: 0.8484 - val_loss: 1.6847 - val_accuracy: 0.5645\n",
      "Epoch 100/100\n",
      "449/449 [==============================] - 277s 617ms/step - loss: 0.4244 - accuracy: 0.8484 - val_loss: 1.5984 - val_accuracy: 0.5773\n"
     ]
    }
   ],
   "source": [
    "X_train,train_y,X_test,test_y=[],[],[],[]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "           X_train.append(np.array(val,'float32'))\n",
    "           train_y.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "           X_test.append(np.array(val,'float32'))\n",
    "           test_y.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")\n",
    "\n",
    "\n",
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "width, height = 48, 48\n",
    "\n",
    "\n",
    "X_train = np.array(X_train,'float32')\n",
    "train_y = np.array(train_y,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "test_y = np.array(test_y,'float32')\n",
    "\n",
    "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
    "\n",
    "#cannot produce\n",
    "#normalizing data between oand 1\n",
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
    "\n",
    "# print(f\"shape:{X_train.shape}\")\n",
    "##designing the cnn\n",
    "#1st convolution layer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "#Compliling the model\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Training the model\n",
    "model.fit(X_train, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True)\n",
    "\n",
    "\n",
    "#Saving the  model to  use it later on\n",
    "fer_json = model.to_json()\n",
    "with open(\"fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")\n",
    "fer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0558c184",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No model config found in the file at <tensorflow.python.platform.gfile.GFile object at 0x000001B8DB5E4040>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16700/3273172693.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mface_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhaarcascades\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34mr'haarcascade_frontalface_default.xml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fer.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0memotion_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Angry'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Disgust'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Fear'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Happy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Neutral'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sad'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Surprise'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\python\\lib\\site-packages\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_config'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'No model config found in the file at {filepath}.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'decode'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m       \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No model config found in the file at <tensorflow.python.platform.gfile.GFile object at 0x000001B8DB5E4040>."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + r'haarcascade_frontalface_default.xml')\n",
    "classifier =load_model(\"fer.h5\")\n",
    "\n",
    "emotion_labels = ['Angry','Disgust','Fear','Happy','Neutral', 'Sad', 'Surprise']\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    labels = []\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_classifier.detectMultiScale(gray)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi_gray = gray[y:y+h,x:x+w]\n",
    "        roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "\n",
    "        if np.sum([roi_gray])!=0:\n",
    "            roi = roi_gray.astype('float')/255.0\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi,axis=0)\n",
    "\n",
    "            prediction = classifier.predict(roi)[0]\n",
    "            label=emotion_labels[prediction.argmax()]\n",
    "            label_position = (x,y-10)\n",
    "            cv2.putText(frame,label,label_position,cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "        else:\n",
    "            cv2.putText(frame,'No Faces',(30,80),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    cv2.imshow('Emotion Detector',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b80f6926",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'cv2.CascadeClassifier' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16700/1582569698.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces_detected\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthickness\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mroi_gray\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgray_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m#cropping region of interest i.e. face area from  image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'cv2.CascadeClassifier' object is not iterable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "\n",
    "#load model\n",
    "model = model_from_json(open(\"fer.json\", \"r\").read())\n",
    "#load weights\n",
    "model.load_weights('fer.h5')\n",
    "\n",
    "\n",
    "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,test_img=cap.read()# captures frame and returns boolean value and captured image\n",
    "    if not ret:\n",
    "        continue\n",
    "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces_detected = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_fullbody.xml')\n",
    "\n",
    "   # face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
    "\n",
    "\n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
    "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
    "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
    "        img_pixels = image.img_to_array(roi_gray)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels /= 255\n",
    "\n",
    "        predictions = model.predict(img_pixels)\n",
    "\n",
    "        #find max indexed array\n",
    "        max_index = np.argmax(predictions[0])\n",
    "\n",
    "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "        predicted_emotion = emotions[max_index]\n",
    "\n",
    "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "    resized_img = cv2.resize(test_img, (1000, 700))\n",
    "    cv2.imshow('Facial emotion analysis ',resized_img)\n",
    "\n",
    "\n",
    "\n",
    "    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37360dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9dbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeeb0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46c342c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b384a0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2876b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
